<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>WebAudioAPI音频重采样 | 吴健强のBLOG</title><meta name="keywords" content="Web WebAudioAPI"><meta name="author" content="吴健强"><meta name="copyright" content="吴健强"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="简介目前的WebCodecs API仅支持对音频文件的解码和编码，并不支持音频重采样操作；如果想要实现对音频的重采样操作的话，可以用Web Audio API中的OfflineAudioContext. 关于OfflineAudioContext的相关内容，具体可参考官方文档； OfflineAudioContext的介绍接下来我们整一段运行在JS主线程的测试代码，用于测试重采样的效率： 1234">
<meta property="og:type" content="article">
<meta property="og:title" content="WebAudioAPI音频重采样">
<meta property="og:url" content="http://example.com/2024/02/02/WebAudioAPI%E9%9F%B3%E9%A2%91%E9%87%8D%E9%87%87%E6%A0%B7/index.html">
<meta property="og:site_name" content="吴健强のBLOG">
<meta property="og:description" content="简介目前的WebCodecs API仅支持对音频文件的解码和编码，并不支持音频重采样操作；如果想要实现对音频的重采样操作的话，可以用Web Audio API中的OfflineAudioContext. 关于OfflineAudioContext的相关内容，具体可参考官方文档； OfflineAudioContext的介绍接下来我们整一段运行在JS主线程的测试代码，用于测试重采样的效率： 1234">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/IronMan/4.jpg">
<meta property="article:published_time" content="2024-02-01T16:00:00.000Z">
<meta property="article:modified_time" content="2024-02-08T12:32:41.560Z">
<meta property="article:author" content="吴健强">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/IronMan/4.jpg"><link rel="shortcut icon" href="/img/IronMan/1.jpg"><link rel="canonical" href="http://example.com/2024/02/02/WebAudioAPI%E9%9F%B3%E9%A2%91%E9%87%8D%E9%87%87%E6%A0%B7/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'WebAudioAPI音频重采样',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-02-08 20:32:41'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/IronMan/3.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">89</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 菜单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/IronMan/2.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">吴健强のBLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 菜单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">WebAudioAPI音频重采样</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-02-01T16:00:00.000Z" title="发表于 2024-02-02 00:00:00">2024-02-02</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-02-08T12:32:41.560Z" title="更新于 2024-02-08 20:32:41">2024-02-08</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="WebAudioAPI音频重采样"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>目前的WebCodecs API仅支持对音频文件的解码和编码，并不支持音频重采样操作；如果想要实现对音频的重采样操作的话，可以用Web Audio API中的OfflineAudioContext.</p>
<p>关于OfflineAudioContext的相关内容，具体可参考<a target="_blank" rel="noopener" href="https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext">官方文档</a>；</p>
<h1 id="OfflineAudioContext的介绍"><a href="#OfflineAudioContext的介绍" class="headerlink" title="OfflineAudioContext的介绍"></a>OfflineAudioContext的介绍</h1><p>接下来我们整一段运行在JS主线程的测试代码，用于测试重采样的效率：</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> audio_Resample_frame_plane_data = [];</span><br><span class="line"><span class="keyword">const</span> offlineContext = <span class="keyword">new</span> <span class="title class_">OfflineAudioContext</span>(<span class="number">2</span>, math.<span class="title function_">ceil</span>(<span class="number">1024</span>*<span class="number">48000</span>/<span class="number">44100</span>), <span class="number">48000</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//According to the decoded frame information, copy the PCM data on each plane</span></span><br><span class="line"><span class="keyword">var</span> audio_frame_plane_data = [];</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; i++) &#123;</span><br><span class="line">  <span class="keyword">let</span> buffer = <span class="keyword">new</span> <span class="title class_">ArrayBuffer</span>(<span class="number">1024</span>);</span><br><span class="line">  audio_frame_plane_data[i] = <span class="keyword">new</span> <span class="title class_">Float32Array</span>(buffer);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> nTestWebCodecAudioDecoderFrameBeginTime = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Counter to track the number of times rendering has completed</span></span><br><span class="line"><span class="keyword">var</span> renderCount = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Fill random numbers into audio data</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; i++) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">let</span> j = <span class="number">0</span>; j &lt; audio_frame_plane_size[i]; j++) &#123;</span><br><span class="line">        audio_frame_plane_data[i][j] = <span class="title class_">Math</span>.<span class="title function_">random</span>() * <span class="number">2</span> - <span class="number">1</span>; <span class="comment">//Random number range is -1 to 1</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//Create AudioBuffer object</span></span><br><span class="line"><span class="keyword">const</span> audioBuffer = offlineContext.<span class="title function_">createBuffer</span>(<span class="number">2</span>, <span class="number">1024</span>, <span class="number">44100</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//Copy the decoded PCM data to the array of each channel</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">let</span> channel = <span class="number">0</span>; channel &lt; audioBuffer.<span class="property">numberOfChannels</span>; channel++) &#123;</span><br><span class="line">    <span class="keyword">const</span> channelData = audioBuffer.<span class="title function_">getChannelData</span>(channel);</span><br><span class="line">    channelData.<span class="title function_">set</span>(audio_frame_plane_data[channel]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">let</span> count = <span class="number">0</span>; count &lt; <span class="number">1</span>; count++) &#123;</span><br><span class="line"></span><br><span class="line">  nTestWebCodecAudioDecoderFrameBeginTime = <span class="keyword">new</span> <span class="title class_">Date</span>().<span class="title function_">getTime</span>().<span class="title function_">toFixed</span>(<span class="number">8</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Start rendering</span></span><br><span class="line">  <span class="keyword">const</span> source = offlineContext.<span class="title function_">createBufferSource</span>();</span><br><span class="line">  source.<span class="property">buffer</span> = audioBuffer;</span><br><span class="line">  source.<span class="title function_">connect</span>(offlineContext.<span class="property">destination</span>);</span><br><span class="line">  source.<span class="title function_">start</span>();</span><br><span class="line">  source.<span class="property">onerror</span> = <span class="keyword">function</span>(<span class="params">error</span>) &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">error</span>(error);</span><br><span class="line">  &#125;;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Listen to the rendering completion event</span></span><br><span class="line">  offlineContext.<span class="title function_">startRendering</span>().<span class="title function_">then</span>(<span class="keyword">function</span>(<span class="params">renderedBuffer</span>) &#123;</span><br><span class="line">        <span class="comment">// Store the resampled data in the array</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">let</span> channel = <span class="number">0</span>; channel &lt; renderedBuffer.<span class="property">numberOfChannels</span>; channel++) &#123;</span><br><span class="line">          <span class="keyword">const</span> channelData = renderedBuffer.<span class="title function_">getChannelData</span>(channel);</span><br><span class="line">          audio_Resample_frame_plane_data.<span class="title function_">push</span>(channelData);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//increment counter</span></span><br><span class="line">        renderCount++;</span><br><span class="line">        <span class="comment">// If all rendering has been completed, perform subsequent operations</span></span><br><span class="line">        <span class="keyword">if</span> (renderCount === <span class="number">100</span>) &#123;</span><br><span class="line">          <span class="keyword">var</span> nTestWebCodecAudioDecoderFrameEndTime = <span class="keyword">new</span> <span class="title class_">Date</span>().<span class="title function_">getTime</span>().<span class="title function_">toFixed</span>(<span class="number">8</span>);</span><br><span class="line">          <span class="keyword">var</span> timeDiff = (nTestWebCodecAudioDecoderFrameEndTime - nTestWebCodecAudioDecoderFrameBeginTime).<span class="title function_">toFixed</span>(<span class="number">8</span>);</span><br><span class="line">          <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;将一百帧44100 2声道的PCM数据重采样成48000 2声道的PCM数据音频数据花费的时间为:&quot;</span> + timeDiff + <span class="string">&quot;毫秒&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看出这段代码是测试重采样一百帧音频数据所花费的时间。由于官方文档关于OfflineAudioContext的细节较少，在网上能查询到的相关博客也相对稀少，因此接下来我们将先通过这段代码，来只要介绍OfflineAudioContext的相关接口的输入参数设置。</p>
<p>首先是：</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> offlineContext = <span class="keyword">new</span> <span class="title class_">OfflineAudioContext</span>(<span class="number">2</span>, math.<span class="title function_">ceil</span>(<span class="number">1024</span>*<span class="number">48000</span>/<span class="number">44100</span>), <span class="number">48000</span>);</span><br></pre></td></tr></table></figure>
<p>这一行代码用于创建一个OfflineAudioContext对象，其中有三个输入参数，第一个输入参数为：输出的PCM数据的声道数（也就是采样后的声道数），第三个输入参数为：输出的PCM数据的采样率（也就是采样后的采样率，即：需要重新采样的采样率）。这里需要注意的是对于输出的PCM数据的采样率是有一定的限制的，必须在8000Hz到96000Hz的范围内，而输出的PCM数据的声道数在官方文档中并没有强调参数的设置范围，不过常用的也基本上是1，2，6，8这几个声道参数。<br>至于第二个输入参数，则需要重点讲一下，根据官方文档，我们可以知道第二个参数是length，指定为音频上下文创建的缓冲区大小（以样本帧为单位），其中一个样本帧是一个单元，可以包含音频数据中每个通道的单个音频数据样本。例如，频率为48000Hz的5秒缓冲区将具有采样帧sampleRate的长度 。5 * 48000 &#x3D; 240000；<br>但是官方文档中并没有说明这个length指的是输入的PCM的数据的length，还是说重采样后输出的PCM的数据的length。一开始我也以为是输入的PCM的数据的length，结果调试的时候发现重采样后的数据长度不对劲，尽然跟源的PCM长度一模一样。因此对于这个输入参数的设置要十分的注意，由于测试代码是将44100 2声道的PCM数据重采样成48000 2声道，而WebCodecs音频解码一个block出来的音频帧没声道的采样个数是1024个，因此做了math.ceil(1024*48000&#x2F;44100)的处理，从而得到输出后的采样个数，并将其指定为音频采样后的缓冲区大小。</p>
<p>接下来是：</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> audioBuffer = offlineContext.<span class="title function_">createBuffer</span>(<span class="number">2</span>, <span class="number">1024</span>, <span class="number">44100</span>);</span><br></pre></td></tr></table></figure>
<p>这一行代码用于创建一个缓冲区，用于存放待采样的PCM数据，这边待采样的PCM数据的声道数为2，采样率为44100，每个声道的采样个数为1024个。</p>
<h1 id="JS的主线程和JS的Wrok线程的数据交互方案设计"><a href="#JS的主线程和JS的Wrok线程的数据交互方案设计" class="headerlink" title="JS的主线程和JS的Wrok线程的数据交互方案设计"></a>JS的主线程和JS的Wrok线程的数据交互方案设计</h1><p>是不是以为这就实现我们需要的重采样功能了？too young too simple，有没有发现为什么我上面在介绍OfflineAudioContext的这段测试代码的时候，要强调这是一段运行在JS主线程的测试代码，因此OfflineAudioContext直能在JS的主线程中才能创建！！！究极蛋疼的一点是，我们的WebCodec的音频解码是运行在JS的Work线程中的，这才是最靠北的地方，我们需要找到一个方案，将JS的Work线程中解码后的音频数据送到JS的主线程中进行重采样操作，等操作完后还需要将重采样后的PCM数据送到JS的Work线程进行位深处理（做位深处理的原因是音频解码后的数据和重采样的输入输出数据全是f32类型的，而我们给解码器的源压缩数据一般都是s16的，如果你想保证C++层输出的音频帧跟源的位深信息保持一致的话，就得做位深转换，当然如果你打通了全链路f32的话那就没必要做位深转换咯），最后再把处理后的音频帧数据从JS的Work线程传递到C++层。<br>因此综上所述：这是一个涉及到JS的主线程，JS的Wrok线程和C++层的复杂数据交互操作，非常的麻烦。而通过之前对WebCodec音频解码插件的开发笔记，我们可以知道C++和JS之间的数据交互采用的是<a target="_blank" rel="noopener" href="https://emscripten.org/">emscripten</a>技术。那JS的主线程和JS的Wrok线程之间的数据交互要用什么来实现呢？答案是<a target="_blank" rel="noopener" href="https://developer.mozilla.org/en-US/docs/Web/API/MessageChannel">MessageChannel</a>+<a target="_blank" rel="noopener" href="https://developer.mozilla.org/en-US/docs/Web/API/Window/postMessage">postMessage</a>.</p>
<h1 id="MessageChannel介绍"><a href="#MessageChannel介绍" class="headerlink" title="MessageChannel介绍"></a>MessageChannel介绍</h1><p>官方文档对MessageChannel的介绍就简简单单的一行：The MessageChannel interface of the Channel Messaging API allows us to create a new message channel and send data through it via its two MessagePort properties.<br>具体来说：MessageChannel是一个消息传递的通道，MessageChannel有两个参数port1和port2，当我们用port1发送数据的时候，port2就能接听和接收到数据，同理port2发送消息的时候，port1也能接听和接收到数据。而MessageChannel可以用于JS不同线程之间的消息传递，因此通过MessageChannel就能实现JS不同线程之间的数据交互操作。</p>
<p>因此我们现在可以设计一套重采样方案：JS的Work线程完成解码操作后，首先通过MessageChannel将解码后的数据从JS的Work线程传递到JS主线程，然后通过emscripten告诉C++层，C++层接收到消息后，通过调用emscripten_sync_run_in_main_runtime_thread接口，强制将重采样的JS函数在JS的主线程中运行，等待重采样结束后，再用MessageChannel将重采样后的数据从JS的主线程传递到JS的Work线程做位深处理，在JS的Work线程做完位深处理后，再通过emscripten将数据传递到C++层。</p>
<p>这个方案看起来虽然复杂（实际上交互也很复杂），但是是不是挺完美？too young too simple.这个方案还有一个问题就是，我们的MessageChannel要在JS的主线程还是JS的Work线程中创建呢？创建后，假如当前线程使用port1的话，那我们要咋将port2告诉另一个线程呢？难不成我们要需要通过C++层来传递port2的值吗？</p>
<p>首先第一个问题MessageChannel要在JS的主线程还是JS的Work线程中创建呢？<br>其实在哪个线程创建都行，前提是如何将port2告诉另一个线程，如果我们在JS的Work线程中创建MessageChannel，那么port1就在Work线程中保持，而port2就需要我们传递给JS的主线程进行保存咯，主要的方案有两个：</p>
<ul>
<li>JS的Work线程通过emscripten将post2传到C++层，C++层调用emscripten_sync_run_in_main_runtime_thread接口，将post2作为某个JS函数的输入参数传递到JS主线程。</li>
<li>通过postMessage将post2直接传递给JS的主线程</li>
</ul>
<p>其中步骤二的参考例程为：<br>在JS的主线程中可以创建一个Web Worker，并监听其message事件。在Web Worker中，可以使用postMessage()方法将数据发送给主线程。</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在主线程中创建Web Worker</span></span><br><span class="line"><span class="keyword">const</span> worker = <span class="keyword">new</span> <span class="title class_">Worker</span>(<span class="string">&#x27;worker.js&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 监听Web Worker的message事件</span></span><br><span class="line">worker.<span class="property">onmessage</span> = <span class="keyword">function</span>(<span class="params">event</span>) &#123;</span><br><span class="line">  <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;Received message from worker:&#x27;</span>, event.<span class="property">data</span>);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 向Web Worker发送数据</span></span><br><span class="line">worker.<span class="title function_">postMessage</span>(<span class="string">&#x27;Hello from main thread!&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p>在Web Worker中，可以监听主线程的message事件，并使用postMessage()方法将数据发送给主线程。</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在Web Worker中监听message事件</span></span><br><span class="line">self.<span class="property">onmessage</span> = <span class="keyword">function</span>(<span class="params">event</span>) &#123;</span><br><span class="line">  <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;Received message from main thread:&#x27;</span>, event.<span class="property">data</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 向主线程发送数据</span></span><br><span class="line">  self.<span class="title function_">postMessage</span>(<span class="string">&#x27;Hello from worker!&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p>这边我将MessageChannel的创建放在JS的主线程中创建（为什么这么干我们后面会讲到），然后通过PThread.pthreads[webcodec_audio_decoder_thread_id];的方式获得JS的Work线程，最后将post1传递给JS的Work线程，而port2存放在JS主线程中的WebCodec_JS_Main_Thread_Audio_Resample_Channel_Port。相关代码如下：</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Call this function in the JS main thread to create a MessageChannel</span></span><br><span class="line"><span class="attr">JS_WebCodecAudioDecoderConfigChannelSendMessage</span>: <span class="keyword">function</span> (<span class="params">audio_decoder_obj_adrr, webcodec_audio_decoder_thread_id</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!<span class="title class_">WebCodecAudioDecoderMsgChannel</span>) &#123;</span><br><span class="line">        <span class="title class_">WebCodecAudioDecoderMsgChannel</span> = <span class="keyword">new</span> <span class="title class_">MessageChannel</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">let</span> targetWorker = <span class="title class_">PThread</span>.<span class="property">pthreads</span>[webcodec_audio_decoder_thread_id];</span><br><span class="line">        targetWorker.<span class="title function_">postMessage</span>(&#123; <span class="attr">msg_type</span>: <span class="string">&quot;GetChannelPort&quot;</span>, <span class="attr">webcodec_audio_decoder_obj_adrr</span>: audio_decoder_obj_adrr &#125;, </span><br><span class="line">            [<span class="title class_">WebCodecAudioDecoderMsgChannel</span>.<span class="property">port1</span>]);</span><br><span class="line"></span><br><span class="line">        <span class="title class_">WebCodec</span>_JS_Main_Thread_Audio_Resample_Channel_Port = <span class="title class_">WebCodecAudioDecoderMsgChannel</span>.<span class="property">port2</span>;</span><br><span class="line">        <span class="comment">// The listening object of the JS main thread: JS_AudioDecoderWaitChannelMessage is used to obtain the data of the audio decoding frame</span></span><br><span class="line">        <span class="title class_">WebCodec</span>_JS_Main_Thread_Audio_Resample_Channel_Port.<span class="title function_">addEventListener</span>(<span class="string">&quot;message&quot;</span>, JS_AudioDecoderWaitChannelMessage);</span><br><span class="line">        <span class="title class_">WebCodec</span>_JS_Main_Thread_Audio_Resample_Channel_Port.<span class="title function_">start</span>();</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;JS_WebCodecAudioDecoderConfigChannelSendMessage&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Add JS_AudioResampleWaitChannelMessage as a listening object in the Work thread of WebCodecAudioDecoder.</span></span><br><span class="line"><span class="attr">JS_AudioResampleAddEventListener</span>: <span class="keyword">function</span> (<span class="params"></span>) &#123;</span><br><span class="line">    self.<span class="title function_">addEventListener</span>(<span class="string">&quot;message&quot;</span>, JS_AudioResampleWaitChannelMessage);</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;JS_AudioResampleAddEventListener&quot;</span>);</span><br><span class="line">&#125;,</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ----------------------------------- Data transfer direction: main thread &lt;-- Work thread----------------------------------- //</span></span><br><span class="line"><span class="keyword">var</span> <span class="title class_">WebCodecAudioDecoderMsgChannel</span> = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">var</span> <span class="title class_">WebCodec</span>_JS_Work_Thread_Audio_Decoder_Channel_Port = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">var</span> <span class="title class_">WebCodec</span>_JS_Main_Thread_Audio_Resample_Channel_Port = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">    The listening object JS_AudioResampleMessage of port2 of MessageChannel (used in the main </span></span><br><span class="line"><span class="comment">    thread of JS to obtain audio decoded data).</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">JS_AudioDecoderWaitChannelMessage</span>(<span class="params">event</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (event.<span class="property">data</span>.<span class="property">type</span> == <span class="string">&#x27;audioDecoderFrameData&#x27;</span>) &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ----------------------------------- Data transfer direction: main thread --&gt; Work thread ----------------------------------- //</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">    The listening object JS_AudioResampleMessage of port1 of MessageChannel (used in the Work thread </span></span><br><span class="line"><span class="comment">    of JS to obtain audio resampled data).</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">JS_AudioResampleMessage</span>(<span class="params">e</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (e.<span class="property">data</span>.<span class="property">type</span> == <span class="string">&#x27;PushResampledAudioDecoderData&#x27;</span>) &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">    The Work thread monitoring object of JS audio decoding is to assign the port1 of the MessageChannel </span></span><br><span class="line"><span class="comment">    created by the main thread to the WebCodec_JS_Work_Thread_Audio_Decoder_Channel_Port of the Wrok thread.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">JS_AudioResampleWaitChannelMessage</span>(<span class="params">e</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (e.<span class="property">data</span>.<span class="property">msg_type</span> == <span class="string">&#x27;GetChannelPort&#x27;</span>) &#123;</span><br><span class="line">        <span class="title class_">WebCodec</span>_JS_Work_Thread_Audio_Decoder_Channel_Port = e.<span class="property">ports</span>[<span class="number">0</span>];</span><br><span class="line">        <span class="comment">// Add the listening object of the JS audio decoding Work thread to monitor the resampling message of the JS main thread.</span></span><br><span class="line">        <span class="title class_">WebCodec</span>_JS_Work_Thread_Audio_Decoder_Channel_Port.<span class="title function_">addEventListener</span>(<span class="string">&quot;message&quot;</span>, JS_AudioResampleMessage);</span><br><span class="line">        <span class="title class_">WebCodec</span>_JS_Work_Thread_Audio_Decoder_Channel_Port.<span class="title function_">start</span>();</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;[JS] JS_AudioResampleWaitChannelMessage &quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">JS_AudioResampleAddEventListener</span>();</span><br><span class="line"><span class="built_in">emscripten_sync_run_in_main_runtime_thread</span>(EM_FUNC_SIG_III, JS_WebCodecAudioDecoderConfigChannelSendMessage, (<span class="type">int</span>)<span class="keyword">this</span>, <span class="built_in">pthread_self</span>());</span><br></pre></td></tr></table></figure>

<p>接下来，我们详细的讲述一下上面的这几段代码：<br>根据程序代码的执行步骤：</p>
<h2 id="步骤一：调用JS-AudioResampleAddEventListener"><a href="#步骤一：调用JS-AudioResampleAddEventListener" class="headerlink" title="步骤一：调用JS_AudioResampleAddEventListener();"></a>步骤一：调用JS_AudioResampleAddEventListener();</h2><p>当我们需要进行重采样操作的时候，首先C++层调用JS_AudioResampleAddEventListener函数，此时JS的Work线程注册了监听对象JS_AudioResampleWaitChannelMessage，后面只要JS的Work线程在监听到消息的话，会自动触发执行JS_AudioResampleWaitChannelMessage函数，而JS_AudioResampleWaitChannelMessage函数的作用是就是获取我们后续在JS主线程中创建的MessageChannel的post1.</p>
<p>PS:</p>
<ul>
<li>注意self.addEventListener(“message”, JS_AudioResampleWaitChannelMessage);这里的self是JS的Work线程（因为我们在C++层调用JS_AudioResampleAddEventListener的时候是直接调用，并没有通过emscripten指定调用其他的线程，因此是运行在JS的Work线程也就是解码所在的线程），而addEventListener()方法用于向指定的元素添加事件监听器。当指定的事件类型在元素上触发时，事件监听器会被调用。在JavaScript中，可以使用addEventListener()方法来监听Web Worker的message事件。message事件在Web Worker接收到来自主线程的消息时触发。</li>
</ul>
<h2 id="步骤二：调用emscripten-sync-run-in-main-runtime-thread-EM-FUNC-SIG-III-JS-WebCodecAudioDecoderConfigChannelSendMessage-int-this-pthread-self"><a href="#步骤二：调用emscripten-sync-run-in-main-runtime-thread-EM-FUNC-SIG-III-JS-WebCodecAudioDecoderConfigChannelSendMessage-int-this-pthread-self" class="headerlink" title="步骤二：调用emscripten_sync_run_in_main_runtime_thread(EM_FUNC_SIG_III, JS_WebCodecAudioDecoderConfigChannelSendMessage, (int)this, pthread_self());"></a>步骤二：调用emscripten_sync_run_in_main_runtime_thread(EM_FUNC_SIG_III, JS_WebCodecAudioDecoderConfigChannelSendMessage, (int)this, pthread_self());</h2><p>接下来，我们在C++层通过emscripten的emscripten_sync_run_in_main_runtime_thread接口强制将JS_WebCodecAudioDecoderConfigChannelSendMessage运行在主线程中，此时在这个JS函数中将会做三件事情：</p>
<ul>
<li>new一个MessageChannel</li>
<li>将MessageChannel的post1通过let targetWorker &#x3D; PThread.pthreads[webcodec_audio_decoder_thread_id];targetWorker.postMessage({ msg_type: “GetChannelPort”, webcodec_audio_decoder_obj_adrr: audio_decoder_obj_adrr }, [WebCodecAudioDecoderMsgChannel.port1]);的方式传递给JS的Work线程</li>
<li>将MessageChannel的post2存放在WebCodec_JS_Main_Thread_Audio_Resample_Channel_Port中，并添加和启动post2的监听，并将JS_AudioDecoderWaitChannelMessage作为监听的响应函数</li>
</ul>
<p>此时在做第二件事情的时候，会触发我们步骤一在Work线程注册的JS_AudioResampleWaitChannelMessage函数，此时JS_AudioResampleWaitChannelMessage函数通过if语句判断是否是e.data.msg_type &#x3D;&#x3D; ‘GetChannelPort’，从而得到post1，并存放到WebCodec_JS_Work_Thread_Audio_Decoder_Channel_Port中，同时对WebCodec_JS_Work_Thread_Audio_Decoder_Channel_Port（也就是MessageChannel的post1添加和启动监听对象JS_AudioResampleMessage，用于接收后面JS主线程重采样结束后传递过来的PCM数据和相关重采样输出数据）</p>
<p>在做第三件事情的时候，添加和启动JS_AudioDecoderWaitChannelMessage为WebCodec_JS_Main_Thread_Audio_Resample_Channel_Port（也就是MessageChannel的post2）的监听对象，JS_AudioDecoderWaitChannelMessage的作用监听JS的Work线程传递过来的PCM解码数据和相关重采样的输入参数。</p>
<p>此时，当JS的Work线程完成当前Block的解码后，即可通过WebCodec_JS_Work_Thread_Audio_Decoder_Channel_Port传递解码后的数据到JS的主线程做重采样处理：</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Call postMessage in the Work thread of the current audio decoding to send a message to the main thread.</span></span><br><span class="line"><span class="keyword">const</span> data = &#123;</span><br><span class="line">  <span class="attr">audio_frame_plane_number</span>: <span class="variable language_">this</span>.<span class="property">codec_channel_number</span>,</span><br><span class="line">  <span class="attr">audio_sample_counts_per_each_plane</span>: audio_sample_counts_per_each_plane,</span><br><span class="line">  <span class="attr">audio_data_per_each_plane</span>: audio_data_per_each_plane</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> message = &#123; <span class="attr">type</span>: <span class="string">&#x27;audioDecoderFrameData&#x27;</span>, </span><br><span class="line">  <span class="attr">audio_decoder_frame_plane_info</span>: data</span><br><span class="line">&#125;;</span><br><span class="line"><span class="title class_">WebCodec</span>_JS_Work_Thread_Audio_Decoder_Channel_Port.<span class="title function_">postMessage</span>(message);</span><br></pre></td></tr></table></figure>
<p>同样JS的主线程重采样完成后也可通过WebCodec_JS_Main_Thread_Audio_Resample_Channel_Port传递重采样的数据到JS的Work线程做位深处理：</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Return the resampled data from the JS main thread to the Work thread</span></span><br><span class="line"><span class="title class_">WebCodec</span>_JS_Main_Thread_Audio_Resample_Channel_Port.<span class="title function_">postMessage</span>(</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">type</span>: <span class="string">&#x27;PushResampledAudioDecoderData&#x27;</span>,</span><br><span class="line">        <span class="attr">webcodec_audio_decoder_obj_adrr</span>: webcodec_audio_decoder_obj_adrr,</span><br><span class="line">        <span class="attr">audio_resample_plane_data</span>: audio_resample_plane_data,</span><br><span class="line">        <span class="attr">audio_resample_plane_number_of_frames</span>: renderedBuffer.<span class="property">length</span>,</span><br><span class="line">        <span class="attr">audio_resample_channels_number</span>: renderedBuffer.<span class="property">numberOfChannels</span>,</span><br><span class="line">        <span class="attr">audio_resample_sample_rate</span>: renderedBuffer.<span class="property">sampleRate</span></span><br><span class="line">    &#125;</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>因此，整个重采样的流程就是：</p>
<ul>
<li>C++层调用JS_AudioResampleAddEventListener();和emscripten_sync_run_in_main_runtime_thread(EM_FUNC_SIG_III, JS_WebCodecAudioDecoderConfigChannelSendMessage, (int)this, pthread_self());完成MessageChannel的创建和相关监听对象的注册工作</li>
<li>当JS的Work线程完成音频帧的解码时，调用WebCodec_JS_Work_Thread_Audio_Decoder_Channel_Port.postMessage(message);将解码后的数据传递给JS的主线程，接着通过emscripte通知C++层需要开始进行重采样处理，此时C++层调用emscripten_sync_run_in_main_runtime_thread(EM_FUNC_SIG_VIIIII,JS_ResampleAudioDecoderFrame,(int)this,m_stWSAudioInfo.channels,m_stWSAudioInfo.sample_rate,m_nChannelsNumberOfAudioDecoderFrameResample,m_nSampleRateOfAudioDecoderFrameResample);将重采样JS函数JS_ResampleAudioDecoderFrame强制指定在JS的主线程中运行，等待重采样结束后通过WebCodec_JS_Main_Thread_Audio_Resample_Channel_Port.postMessage将重采样后的数据发送到JS的Work线程中做进一步的位深处理，最后JS的Wrok线程再通过emscripten将做完位深处理后的数据传递到C++层。</li>
</ul>
<p>这边可能有人会疑惑，既然原本的<a target="_blank" rel="noopener" href="https://developer.mozilla.org/en-US/docs/Web/API/Window/postMessage">window.postMessage()</a>技术就能进行JS的主线程和其他线程的交互工作，为什么还要多此一举的通过window.postMessage()将MessageChannel的post1传递给JS的Work线程，然后后续的重采样的交互操作再通过MessageChannel的post1和post2来实现？这个主要的原因是由于我们现在开发的是音频解码和重采样，如果都通过window.postMessage()来进行消息监听和传递的话，鬼知道会不会跟其他的功能模块冲突了，比如要是有模块的e.data.msg_type 都是 ‘GetChannelPort’的话，那不就消息冲突了，这样排查起来不得爆炸，因为我们最好别搞什么通过window.postMessage()直接从JS子线程向JS的主线程传递消息的骚操作，不然到时候炸了排查到吐血，因为这也是为什么我一开始说的我们后面会讲到：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这边我将MessageChannel的创建放在JS的主线程中创建，然后通过PThread.pthreads[webcodec_audio_decoder_thread_id];的方式获得JS的Work线程，最后将post1传递给JS的Work线程，而port2存放在JS主线程中的WebCodec_JS_Main_Thread_Audio_Resample_Channel_Port。</span><br></pre></td></tr></table></figure>
<p>这样做的好处是：我们此时post1的传递是通过JS的主线程的window.postMessage()向JS的WebCodecsAudioDecoder线程传递，而不是反过来的操作，因此就避免了后续可能出现的消息冲突的爆炸问题！！！</p>
<h1 id="重采样的具体代码实现以及相关注意事项"><a href="#重采样的具体代码实现以及相关注意事项" class="headerlink" title="重采样的具体代码实现以及相关注意事项"></a>重采样的具体代码实现以及相关注意事项</h1><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">JS_ResampleAudioDecoderFrame</span>: <span class="keyword">function</span> (<span class="params">webcodec_audio_decoder_obj_adrr,src_channels_number,src_sample_rate,dst_channels_number,dst_sample_rate</span>)&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Promise</span>(<span class="keyword">function</span>(<span class="params">resolve, reject</span>) &#123;</span><br><span class="line">      <span class="comment">// Determine whether the browser supports OfflineAudioContext</span></span><br><span class="line">      <span class="keyword">const</span> <span class="title class_">OfflineAudioContext</span> = <span class="variable language_">window</span>.<span class="property">OfflineAudioContext</span> || <span class="variable language_">window</span>.<span class="property">webkitOfflineAudioContext</span>;</span><br><span class="line">      <span class="keyword">if</span> (!<span class="title class_">OfflineAudioContext</span>) &#123;</span><br><span class="line">          <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&#x27;OfflineAudioContext is not supported in this browser&#x27;</span>);</span><br><span class="line">          <span class="keyword">return</span> <span class="title class_">Promise</span>.<span class="title function_">reject</span>(<span class="keyword">new</span> <span class="title class_">Error</span>(<span class="string">&#x27;OfflineAudioContext is not supported in this browser&#x27;</span>));</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">          <span class="comment">// Create OfflineAudioContext object，</span></span><br><span class="line">          <span class="comment">//Since OfflineAudioContext will be closed every time it completes rendering, it has to be recreated every time and cannot be reused! ! !</span></span><br><span class="line">          <span class="title class_">WebCodec</span>_JS_Main_Thread_Audio_Resample_Offline_Context = <span class="keyword">new</span> <span class="title class_">OfflineAudioContext</span>(dst_channels_number,(audio_sample_counts_per_each_plane[<span class="number">0</span>] /src_sample_rate)*dst_sample_rate, dst_sample_rate);</span><br><span class="line"></span><br><span class="line">          <span class="comment">// Create an AudioBuffer object to store the decoded audio PCM data</span></span><br><span class="line">          <span class="keyword">const</span> audioBuffer = <span class="title class_">WebCodec</span>_JS_Main_Thread_Audio_Resample_Offline_Context.<span class="title function_">createBuffer</span>(src_channels_number, audio_sample_counts_per_each_plane[<span class="number">0</span>], src_sample_rate);</span><br><span class="line"></span><br><span class="line">          <span class="comment">// Copy the decoded PCM data to the array of each channel</span></span><br><span class="line">          <span class="keyword">for</span> (<span class="keyword">let</span> channel = <span class="number">0</span>; channel &lt; audioBuffer.<span class="property">numberOfChannels</span>; channel++) &#123;</span><br><span class="line">              <span class="keyword">const</span> channelData = audioBuffer.<span class="title function_">getChannelData</span>(channel);</span><br><span class="line">              channelData.<span class="title function_">set</span>(audio_data_per_each_plane[channel]);</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          <span class="comment">// Start rendering</span></span><br><span class="line">          <span class="keyword">const</span> source = <span class="title class_">WebCodec</span>_JS_Main_Thread_Audio_Resample_Offline_Context.<span class="title function_">createBufferSource</span>();</span><br><span class="line">          source.<span class="property">buffer</span> = audioBuffer;</span><br><span class="line"></span><br><span class="line">          source.<span class="title function_">connect</span>(<span class="title class_">WebCodec</span>_JS_Main_Thread_Audio_Resample_Offline_Context.<span class="property">destination</span>);</span><br><span class="line">          source.<span class="title function_">start</span>();</span><br><span class="line">          source.<span class="property">onerror</span> = <span class="keyword">function</span>(<span class="params">error</span>) &#123;</span><br><span class="line">              <span class="variable language_">console</span>.<span class="title function_">error</span>(error);</span><br><span class="line">          &#125;;</span><br><span class="line"></span><br><span class="line">          <span class="comment">// Asynchronous callback</span></span><br><span class="line">          <span class="title class_">WebCodec</span>_JS_Main_Thread_Audio_Resample_Offline_Context.<span class="title function_">startRendering</span>().<span class="title function_">then</span>(<span class="keyword">function</span>(<span class="params">renderedBuffer</span>) &#123;</span><br><span class="line"></span><br><span class="line">              <span class="comment">// Store the resampled data in the array</span></span><br><span class="line">              <span class="keyword">for</span> (<span class="keyword">let</span> channel = <span class="number">0</span>; channel &lt; renderedBuffer.<span class="property">numberOfChannels</span>; channel++) &#123;</span><br><span class="line">                  <span class="keyword">const</span> channelData = renderedBuffer.<span class="title function_">getChannelData</span>(channel);</span><br><span class="line">                  audio_resample_plane_data[channel] = <span class="keyword">new</span> <span class="title class_">Float32Array</span>(channelData);</span><br><span class="line">              &#125;</span><br><span class="line"></span><br><span class="line">              <span class="comment">// Return the resampled data from the JS main thread to the Work thread</span></span><br><span class="line">              <span class="title class_">WebCodec</span>_JS_Main_Thread_Audio_Resample_Channel_Port.<span class="title function_">postMessage</span>(</span><br><span class="line">                  &#123;</span><br><span class="line">                      <span class="attr">type</span>: <span class="string">&#x27;PushResampledAudioDecoderData&#x27;</span>,</span><br><span class="line">                      <span class="attr">webcodec_audio_decoder_obj_adrr</span>: webcodec_audio_decoder_obj_adrr,</span><br><span class="line">                      <span class="attr">audio_resample_plane_data</span>: audio_resample_plane_data,</span><br><span class="line">                      <span class="attr">audio_resample_plane_number_of_frames</span>: renderedBuffer.<span class="property">length</span>,</span><br><span class="line">                      <span class="attr">audio_resample_channels_number</span>: renderedBuffer.<span class="property">numberOfChannels</span>,</span><br><span class="line">                      <span class="attr">audio_resample_sample_rate</span>: renderedBuffer.<span class="property">sampleRate</span></span><br><span class="line">                  &#125;</span><br><span class="line">              );</span><br><span class="line">          &#125;);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">catch</span> (error) &#123;</span><br><span class="line">          <span class="variable language_">console</span>.<span class="title function_">error</span>(error);</span><br><span class="line">          <span class="title function_">reject</span>(error);</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>

<p>到此基本上重采样的功能已经实现了，你是不是也这样以为呢?too young too simple!!!</p>
<p>这边还有一个大坑，不注意的话就掉进去了，我们在最开始讲重采样测试代码的时候说了：由于测试代码是将44100 2声道的PCM数据重采样成48000 2声道，而WebCodecs音频解码一个block出来的音频帧没声道的采样个数是1024个，因此做了math.ceil(1024*48000&#x2F;44100)的处理，从而得到输出后的采样个数，并将其指定为音频采样后的缓冲区大小。</p>
<p>此时，我们想想这样搞是不是有点小问题？按照测试代码，源是44100的采样率，每帧源数据的每个声道的采样个数是1024,而目的帧的采样率是48000，那么目的帧每个声道的采样个数X的计算公式是：1024&#x2F;X &#x3D; 44100&#x2F;48000,也就是x &#x3D; 1114.55782,不能被整除，如果我们直接将每次解码后的数据直接送去重采样的话，那么拿到的重采样后的数据长度是不对劲的，如果你像测试代码一样利用math.ceil做了向上取整的话或者是向下取整的话，都不能保证最终生成的整个重采样后的PCM数据是48000的采样率，声音听起来也会有细微的噪点！！！</p>
<p>因此这边你需要干的时候是送去重采样的数据是能被整除的数据，这就意味着你必须在JS层创建一个缓冲区，用于存放解码后的音频数据，直到满足一定的大小要求后再将数据送到JS主线程做重采样处理，并且重采样处理后的数据你还得做拆包处理，并且重新计算pts和duration！！！<br>而这边重采样的条件是什么呢？最简单粗暴的方式是假如源是44100的采样率的话，我们我送过去采样的每个声道的采样个数就是44100，也就是每次我都送1s的源PCM数据过去重采样，那么肯定能被整除了，但是一个block解码出来每个声道的采样个数才1024个大小，如果你源是44100的话，那开辟的缓冲区就得存放44帧的解码数据，这样有个问题就是当应用层每次进行seek操作的时候，你都得把这么大的一个缓冲区全给清空了，并且seek后第一个取帧的话，又得等你填满这个缓冲区后并且完成重采样和位深处理后应用层才能拿到seek后的那帧数据，这个效率爆炸低！<br>那么我们有什么方式来提高效率吗？答案就是保证每次送去重采样的数据量既可以被整除又尽可能的小，那么我们就回到了一开始OfflineAudioContext的第三个输入参数的上了，通过官方文档可知OfflineAudioContext支持的重采样范围为8000Hz到96000Hz，因此我们要找到而无论是8000Hz、96000Hz，还是我们常见的44100Hz、48000Hz均能被整除的一个数，及公约数</p>
<p>这边可供我们的最好的选择是25，25这个数字刚好能被常用的采样率整除，而将一秒的PCM数据拆分成25个包又容易计算pts和duration值，每个包的duration刚好是1&#x2F;25,小数点后可以除净，因此我们可以采用这个方式设置缓冲区的大小，即缓冲区的大小为：源采样率&#x2F;25,当缓冲区填满后立马开始重采样操作！！！这样就能最高效率的实现WEbCodecs的音频解码+音频重采样+位深处理的方案设计！！！</p>
<p>但是还有一个问题不知道大家有没有想到？万一这个文件的pts不是严格递增的呢？我们如果简单粗暴的采用,duration&#x3D;1s&#x2F;25;pts&#x3D;num＊duration的方式,可能就会出现音视频没有对齐的现象咯；因此我们在进行重采用的处理之前，还需要对解码后的音频帧进行处理，以确保音视频文件的对齐．如何处理呢？简单来说就是需要保证在重采样的数据必须是连续的。因此需要对解码后的音频帧的pts和durationß做一定的判断，来确保重采样的输入缓冲区内数据为连续pcm数据</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">吴健强</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2024/02/02/WebAudioAPI%E9%9F%B3%E9%A2%91%E9%87%8D%E9%87%87%E6%A0%B7/">http://example.com/2024/02/02/WebAudioAPI音频重采样/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">吴健强のBLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/IronMan/4.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/assets/img/weixinpay.jpeg" target="_blank"><img class="post-qr-code-img" src="/assets/img/weixinpay.jpeg"/></a><div class="post-qr-code-desc"></div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2024/02/02/%E9%9F%B3%E8%A7%86%E9%A2%91%E7%BC%96%E8%A7%A3%E7%A0%81%E5%BC%95%E6%93%8E%E4%B9%8B%E5%A4%9A%E8%B7%AF%E6%B5%81%E8%BD%AC%E6%8D%A2%E6%A8%A1%E5%9D%97%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"><img class="next-cover" src="/img/IronMan/7.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">音视频编解码引擎之多路流转换模块的架构设计</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/IronMan/3.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">吴健强</div><div class="author-info__description">吴健强のBLOG</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">89</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/wujianqiangCode"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/wujianqiangCode" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:ijianqiangwu@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/assets/img/qq.jpg" target="_blank" title="QQ"><i class="fab fa-qq"></i></a><a class="social-icon" href="/assets/img/weixin.jpeg" target="_blank" title="微信"><i class="fab fa-weixin"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#OfflineAudioContext%E7%9A%84%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.</span> <span class="toc-text">OfflineAudioContext的介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#JS%E7%9A%84%E4%B8%BB%E7%BA%BF%E7%A8%8B%E5%92%8CJS%E7%9A%84Wrok%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%95%B0%E6%8D%AE%E4%BA%A4%E4%BA%92%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1"><span class="toc-number">3.</span> <span class="toc-text">JS的主线程和JS的Wrok线程的数据交互方案设计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MessageChannel%E4%BB%8B%E7%BB%8D"><span class="toc-number">4.</span> <span class="toc-text">MessageChannel介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E8%B0%83%E7%94%A8JS-AudioResampleAddEventListener"><span class="toc-number">4.1.</span> <span class="toc-text">步骤一：调用JS_AudioResampleAddEventListener();</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E8%B0%83%E7%94%A8emscripten-sync-run-in-main-runtime-thread-EM-FUNC-SIG-III-JS-WebCodecAudioDecoderConfigChannelSendMessage-int-this-pthread-self"><span class="toc-number">4.2.</span> <span class="toc-text">步骤二：调用emscripten_sync_run_in_main_runtime_thread(EM_FUNC_SIG_III, JS_WebCodecAudioDecoderConfigChannelSendMessage, (int)this, pthread_self());</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%87%8D%E9%87%87%E6%A0%B7%E7%9A%84%E5%85%B7%E4%BD%93%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">5.</span> <span class="toc-text">重采样的具体代码实现以及相关注意事项</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/02/02/WebAudioAPI%E9%9F%B3%E9%A2%91%E9%87%8D%E9%87%87%E6%A0%B7/" title="WebAudioAPI音频重采样"><img src="/img/IronMan/4.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="WebAudioAPI音频重采样"/></a><div class="content"><a class="title" href="/2024/02/02/WebAudioAPI%E9%9F%B3%E9%A2%91%E9%87%8D%E9%87%87%E6%A0%B7/" title="WebAudioAPI音频重采样">WebAudioAPI音频重采样</a><time datetime="2024-02-01T16:00:00.000Z" title="发表于 2024-02-02 00:00:00">2024-02-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/02/02/%E9%9F%B3%E8%A7%86%E9%A2%91%E7%BC%96%E8%A7%A3%E7%A0%81%E5%BC%95%E6%93%8E%E4%B9%8B%E5%A4%9A%E8%B7%AF%E6%B5%81%E8%BD%AC%E6%8D%A2%E6%A8%A1%E5%9D%97%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/" title="音视频编解码引擎之多路流转换模块的架构设计"><img src="/img/IronMan/7.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="音视频编解码引擎之多路流转换模块的架构设计"/></a><div class="content"><a class="title" href="/2024/02/02/%E9%9F%B3%E8%A7%86%E9%A2%91%E7%BC%96%E8%A7%A3%E7%A0%81%E5%BC%95%E6%93%8E%E4%B9%8B%E5%A4%9A%E8%B7%AF%E6%B5%81%E8%BD%AC%E6%8D%A2%E6%A8%A1%E5%9D%97%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/" title="音视频编解码引擎之多路流转换模块的架构设计">音视频编解码引擎之多路流转换模块的架构设计</a><time datetime="2024-02-01T16:00:00.000Z" title="发表于 2024-02-02 00:00:00">2024-02-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/01/16/%E9%9F%B3%E8%A7%86%E9%A2%91%E8%A7%A3%E5%A4%8D%E7%94%A8%E6%8F%92%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B9%8B%E8%A7%A3%E5%A4%8D%E7%94%A8%E6%8F%92%E4%BB%B6%E7%AE%A1%E7%90%86%E5%99%A8%E7%9A%84%E8%AE%BE%E8%AE%A1/" title="音视频解复用插件系统的架构设计之解复用插件管理器的设计"><img src="/img/IronMan/8.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="音视频解复用插件系统的架构设计之解复用插件管理器的设计"/></a><div class="content"><a class="title" href="/2024/01/16/%E9%9F%B3%E8%A7%86%E9%A2%91%E8%A7%A3%E5%A4%8D%E7%94%A8%E6%8F%92%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B9%8B%E8%A7%A3%E5%A4%8D%E7%94%A8%E6%8F%92%E4%BB%B6%E7%AE%A1%E7%90%86%E5%99%A8%E7%9A%84%E8%AE%BE%E8%AE%A1/" title="音视频解复用插件系统的架构设计之解复用插件管理器的设计">音视频解复用插件系统的架构设计之解复用插件管理器的设计</a><time datetime="2024-01-15T16:00:00.000Z" title="发表于 2024-01-16 00:00:00">2024-01-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/01/14/%E9%9F%B3%E8%A7%86%E9%A2%91%E8%A7%A3%E5%A4%8D%E7%94%A8%E6%8F%92%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B9%8B%E8%A7%A3%E5%A4%8D%E7%94%A8%E6%8F%92%E4%BB%B6%E7%9A%84%E8%AE%BE%E8%AE%A1/" title="音视频解复用插件系统的架构设计之解复用插件的设计"><img src="/img/IronMan/7.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="音视频解复用插件系统的架构设计之解复用插件的设计"/></a><div class="content"><a class="title" href="/2024/01/14/%E9%9F%B3%E8%A7%86%E9%A2%91%E8%A7%A3%E5%A4%8D%E7%94%A8%E6%8F%92%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B9%8B%E8%A7%A3%E5%A4%8D%E7%94%A8%E6%8F%92%E4%BB%B6%E7%9A%84%E8%AE%BE%E8%AE%A1/" title="音视频解复用插件系统的架构设计之解复用插件的设计">音视频解复用插件系统的架构设计之解复用插件的设计</a><time datetime="2024-01-13T16:00:00.000Z" title="发表于 2024-01-14 00:00:00">2024-01-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/01/10/%E9%9F%B3%E8%A7%86%E9%A2%91%E8%A7%A3%E5%A4%8D%E7%94%A8%E6%8F%92%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B9%8B%E5%AA%92%E4%BD%93%E4%BF%A1%E6%81%AF%E7%9A%84%E6%8F%92%E4%BB%B6%E8%AE%BE%E8%AE%A1/" title="音视频解复用插件系统的架构设计之媒体信息的插件设计"><img src="/img/IronMan/7.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="音视频解复用插件系统的架构设计之媒体信息的插件设计"/></a><div class="content"><a class="title" href="/2024/01/10/%E9%9F%B3%E8%A7%86%E9%A2%91%E8%A7%A3%E5%A4%8D%E7%94%A8%E6%8F%92%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B9%8B%E5%AA%92%E4%BD%93%E4%BF%A1%E6%81%AF%E7%9A%84%E6%8F%92%E4%BB%B6%E8%AE%BE%E8%AE%A1/" title="音视频解复用插件系统的架构设计之媒体信息的插件设计">音视频解复用插件系统的架构设计之媒体信息的插件设计</a><time datetime="2024-01-09T16:00:00.000Z" title="发表于 2024-01-10 00:00:00">2024-01-10</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/IronMan/2.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By 吴健强</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><div class="aplayer no-destroy" data-id="66641056" data-server="netease" data-type="playlist" data-fixed="true" data-autoplay="true" data-lrcType="-1"> </div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>